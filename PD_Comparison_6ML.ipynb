{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8933f1d7-5b01-49ab-9c32-d52eefe92a83",
   "metadata": {},
   "source": [
    "Cristescu Adrian Iulian\n",
    "\n",
    "# Logistic Regression of a portfolio.\n",
    "________________\n",
    "### The objective of this exercise is to find, with logistic regression, which on the regressors impact the most the Probability of Default (PD) after 90 days.\n",
    "______\n",
    "Dataset: 3.364 rows of full data (no blank values)\n",
    "The dataset contains the information of around 3300 individuals and the exercise is trying to predict the default or non default of the variable \"BAD\" which indicates 0 for NON-Default and 1 for Default.\n",
    "____________\n",
    "The considered variables on the dataset are:\n",
    "\n",
    "- BAD: 1 = applicant defaulted on loan or seriously delinquent; 0 = applicant paid loan\n",
    "- LOAN: Amount of the loan request\n",
    "- MORTDUE: Amount due on existing mortgage\n",
    "- VALUE: Value of current property\n",
    "- REASON: DebtCon = debt consolidation; HomeImp = home improvement\n",
    "- JOB: Occupational categories\n",
    "- YOJ: Years at present job\n",
    "- DEROG: Number of major derogatory reports\n",
    "- DELINQ: Number of delinquent credit lines\n",
    "- CLAGE: Age of oldest credit line in months\n",
    "- NINQ: Number of recent credit inquiries\n",
    "- CLNO: Number of credit lines\n",
    "- DEBTINC: Debt-to-income ratio\n",
    "\n",
    "H. Scheule, D. Roesch, B. Baesens, Credit Risk Analytics: The R Companion, Scheule Roesch Baesens, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72261898-3404-4d3b-8d87-03626380fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, roc_curve,classification_report\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from scipy.stats import zscore\n",
    "from imblearn.over_sampling import SMOTE , BorderlineSMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from sklearn.svm import SVC\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457c360-d28c-44d7-85cf-4faebff1f0d8",
   "metadata": {},
   "source": [
    "__________________\n",
    "### Let's see how many rows we have and also drop the rows with empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d178e8-a96f-46f0-847c-a6b1fd1b3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = pd.read_csv('hmeq.csv')\n",
    "# Separate rows with 0 and 1 values in the 'BAD' column\n",
    "#zeros = databeforecut[databeforecut['BAD'] == 0]\n",
    "#ones = databeforecut[databeforecut['BAD'] == 1]\n",
    "\n",
    "# Randomly sample 10% of the rows with 0 values\n",
    "#sampled_zeros = zeros.sample(frac=0.32, random_state=0)\n",
    "\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2159535-6df0-4f2d-bd44-cf201f6d305d",
   "metadata": {},
   "source": [
    "______________\n",
    "### Define the categorical values: Job profession and Reason of loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d479b378-6fa5-451d-953a-dabbfe69ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define manual mapping dictionaries for 'REASON' and 'JOB'\n",
    "reason_mapping_manual = {'DebtCon': 0, 'HomeImp': 1}  # Assigning numbers starting from 0\n",
    "job_mapping_manual = {'Other': 0, 'Office': 1, 'Mgr': 2, 'ProfExe': 3, 'Sales': 4, 'Self': 5}  # Assigning numbers starting from 0\n",
    "\n",
    "# Apply manual mapping for 'REASON' and 'JOB'\n",
    "data['REASON'] = data['REASON'].map(reason_mapping_manual)\n",
    "data['JOB'] = data['JOB'].map(job_mapping_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ed3d7-b189-403c-905c-d5932f37e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format  # Format float values to 2 decimals\n",
    "pd.set_option('display.max_columns', None)  # Show all columns without truncating\n",
    "pd.set_option('display.width', 1000)  # Control width to avoid line breaks\n",
    "\n",
    "# Show the descriptive statistics\n",
    "stats = data.describe()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54295fa4-2c0e-43b6-be0a-3665ea8c2ffa",
   "metadata": {},
   "source": [
    "______________\n",
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee1c69-6b63-4804-b609-3cf29269cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data=data.corr()\n",
    "m_data.style.background_gradient(cmap='viridis', axis=None, low=0, high=1, vmin=-1, vmax=1, subset=None).format(\"{:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04989e83-6e6d-4ea7-8085-9506b4d96f1f",
   "metadata": {},
   "source": [
    "### Let's see the difference of Defaults and Non Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690fff69-4ccc-4fa5-a5f7-8886cf26c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the variable we want to regress against, which is default after 90 days\n",
    "X = data.drop('BAD', axis=1) #we remove the \"default>90days\" variable and we plot it as dependent variable below\n",
    "y = data['BAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d0f9e-b0fc-406f-b142-f89c857bf966",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[data['BAD'].isin([0, 1])]\n",
    "value_counts = filtered_data['BAD'].value_counts()\n",
    "colors = ['blue' if x == 0 else 'red' for x in value_counts.index]\n",
    "plt.bar(value_counts.index, value_counts.values, color=colors)\n",
    "for i, v in enumerate(value_counts.values):\n",
    "    plt.text(i, v + 10, str(v), color='black', ha='center')\n",
    "plt.xlabel('BAD')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Counts of BAD Values')\n",
    "plt.xticks(value_counts.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bea2b6-0ddd-49ed-8a7d-dccbb7a19df8",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### We start training the model. We have:\n",
    "- **Training Set**: Used to train the machine learning model by providing labeled data for learning patterns and relationships between features and target outputs.\n",
    "- **Validation Set**: Used to assess and tune the model during training, ensuring it generalizes well to unseen data by evaluating its performance on data not used in training.\n",
    "- **Test Set**: Used to provide an unbiased evaluation of the final trained model's performance on completely unseen data, measuring how well it generalizes to new observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84e89e2-ecd9-4cda-9b13-83aa66f6473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)  # 30% test set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42, stratify=y_temp)  # 33% val, 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46735a5-d973-4afc-b7d9-1cf62d2d36d3",
   "metadata": {},
   "source": [
    "- In the first sentence we say that 70% of the dataset is used for training and the rest of 30% is put aside\n",
    "- in the second sentence we further split the temporary set into a validation and test set, amounting at 33%.\n",
    "- The stratification parameter ensures that the class distribution in y is preserved in both splits, keeping representative samples across all sets. This ensures that since Defaults and Non-Defaults aren't uniform (different number of observations). By using stratification we enture that the proportion of observations are mantained during the training. In our case, the ratio is almost 10 to 1, hence, during the training, the sets keep this ratio.\n",
    "- ---------------------\n",
    "### SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "    - We generate synthetic examples of the minority class by interpolating between existing minority class instances. This technique helps balance class distribution in imbalanced datasets (ours) by enhancing the model's ability to learn from minority class examples without introducing biaqs frim simply duplication data points.\n",
    "    - The synthetic examples are generated by selecting the minority class (Default) instance at random and computing the k-nearest neighbors for this instance. The examples are then created along the line segments joining these neighbors. \n",
    "\n",
    "## Step 1:\n",
    "### SMOTE - BORDERLINE\n",
    "    - We use a particular type of SMOTE: the Borderline version. This type manages better the wrong classification problem of the minority class which is located near the border between classes. These cohorts are difficult to classify, hence, they have higher probability of being classified wrongly by models. Borderline SMOTE focuses on the generation of synthetic cohorts near the borderline of minority/majority classes. It adresses the istances that are more difficult to classify. \n",
    "    \n",
    "## Step 2:\n",
    "### Data Normalization\n",
    "    - StandardScaler is used to ensure all features are on the same scale, aiding machine learning models to their performance and convergence.\n",
    "\n",
    "## Step 3:\n",
    "### Transform back to DataFrame\n",
    "    - We now transform back the normalized data into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b496c5a7-425f-4039-9f92-0b5f06a3a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#Apply SMOTE (Synthetic minority oversampling technique)\n",
    "smote=BorderlineSMOTE(sampling_strategy='minority', kind='borderline-1')\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Step 2\n",
    "#normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_sm)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Step 3\n",
    "# Convert the scaled data back to DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aafe7e-9633-4948-8290-70b4b56c48e9",
   "metadata": {},
   "source": [
    "______________________\n",
    "# MODELS - Introduction of used terms and metrics\n",
    "- **ROC Curve** : Receiver Operating Characteristic Curve\n",
    "  - It is a graphical representation of the performance of a binary classifier system as its discrimination threshold is varied.\n",
    "  - It plots the True Positive Rate against False Positive Rate ar various threshold settings.\n",
    "  - A diagonal ROC represents random guessing, while an ideal classifier will have its ROC curve reaching the top-left corner of the plot.\n",
    "- **AUC** : Area under the ROC Curve\n",
    "  - It quantifies the overall performance of a binary classification model based on its ability to discriminate between positive and negative examples.\n",
    "  - AUC ranges from 0 to 1, where an AUC of 0.5 indicates a model that performs no better than random, and an AUC of 1 indicates a perfect classifier.\n",
    "  - A higher AUC value generally indicates a better-performing model in terms of its ability to distinguish between positive and negative classes.\n",
    "- **Validation Set** : it is used during model training to tune hyperparameters. Different combinations of parameters are insertet manually until the AUC for the Validation Set is high. After the best parameters are found, they are inserted as unique parameters for the final test set.\n",
    "- **Test Set** : This set is used only once after the parameters has been chosen.\n",
    "- **Precision** : The proportion of true positive predictions among all positive predictions made. It indicates how many selected items are relevant:\n",
    "  - $\\frac{True Positives}{True Positives + False Positives}$\n",
    "- **Accuracy** : The proportion of true positive and true negative predictions among all predictions made. It indicates the overall correctness of the model:\n",
    "  - $\\frac{True Positives + True Negatives}{Total Predictions}$\n",
    "- **Recall** : The proportion of true positive predictions among all actual positive cases. It indicates how many relevant items are selected.\n",
    "  - $\\frac{True Positives}{True Positives + False Negatives}$\n",
    "- **F1-Score** : The harmonic mean of precision and recall. It balances the two metrics, providing a single measure of a test's accuracy.\n",
    "  - $\\frac{Precision \\times Recall}{Precision + Recall}$\n",
    "- **CV - Cross Validation** : In every model, there is the \"grid_search\" code which join the estimators with the chosen model. There is also the metric \"cv\" which is the cross-validation. For every mode I've chosen 10 cv, which means it divides the set in 10 splits and performs the tests on them, averaging the result in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6181fc-1876-47fc-8724-40a75e4fd0e8",
   "metadata": {},
   "source": [
    "### Predicted Probabilities: How are they computed?\n",
    "#### Logistic Regression:\n",
    "\n",
    "After training, when making predictions on new data $( X_{\\text{test}} )$, the model computes a linear combination of the input features weighted by learned coefficients. This linear combination is transformed using the logistic (sigmoid) function:\n",
    "\n",
    "- \\[$$ P(y = 1 \\mid X) = \\frac{1}{1 + e^{-\\left(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_n X_n\\right)}} $$]\n",
    "\n",
    "##### Explanation:\n",
    "- $( \\beta_0, \\beta_1, \\ldots, \\beta_n )$ are the coefficients learned during training.\n",
    "- $( X_1, X_2, \\ldots, X_n )$ are the features of the new data point.\n",
    "\n",
    "##### Output:\n",
    "- The result of the sigmoid function gives the predicted probability \\[$P(y=1 \\mid X)$], which represents the model’s confidence that the output $( y )$ (default/non-default, in this case) is 1 (default) given the features $ (X) $]\n",
    "t.\n",
    "point.\n",
    "a point.\n",
    " point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce77818-47a6-4fd9-9187-3160cfa9d1d2",
   "metadata": {},
   "source": [
    "______________________________\n",
    "#### Decision Tree\n",
    "\n",
    "A Decision Tree makes predictions by traversing from the root of the tree to a leaf node, making decisions at each node. The predicted probability of a class is the proportion of samples of that class in the leaf node:\n",
    "\n",
    "\\[ $P(y = c \\mid X) = \\frac{N_c}{N}$ \\]\n",
    "\n",
    "where $N_c$ is the number of samples of class $c$ in the leaf node and $N$ is the total number of samples in the leaf node.\n",
    "\n",
    "_________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08a2d2-4820-4d71-a001-9b2581c58ff4",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "Random Forest predicts probabilities by averaging the probabilities predicted by each individual tree in the forest. For a binary classification problem:\n",
    "\n",
    "$$\\[ P(y = 1 \\mid X) = \\frac{1}{T} \\sum_{t=1}^{T} P_t(y = 1 \\mid X) \\]$$\n",
    "\n",
    "where $T$ is the number of trees in the forest and $P_t(y = 1 \\mid X)$ is the probability predicted by the $t$-th tree.\n",
    "\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0258273-197b-4fc1-814a-36bc55b6722f",
   "metadata": {},
   "source": [
    "#### AdaBoost\n",
    "\n",
    "AdaBoost computes the predicted probabilities by combining the weighted predictions of weak classifiers. The weight of each classifier depends on its accuracy. The final prediction is given by:\n",
    "\n",
    "$$\\[ F(x) = \\sum_{m=1}^{M} \\alpha_m h_m(x) \\]$$\n",
    "\n",
    "where $M$ is the number of classifiers, $\\alpha_m$ is the weight of the $m$-th classifier, and $h_m(x)$ is the prediction of the $m$-th classifier. The predicted probabilities are then given by:\n",
    "\n",
    "$$\\[ P(y = 1 \\mid X) = \\frac{1}{1 + e^{-F(x)}} \\]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c686756-3539-49bb-8f0f-1056ce9f039e",
   "metadata": {},
   "source": [
    "_____________________________\n",
    "#### Gradient Boosting\n",
    "\n",
    "Similarly, predicts probabilities indirectly through a score $F(x)$, which is the cumulative sum of predictions from individual trees, weighted by learning rates $\\eta$:\n",
    "\n",
    "$$\\[ F(x) = \\sum_{m=1}^{M} \\eta \\cdot h_m(x) \\]$$\n",
    "\n",
    "where $h_m(x)$ is the prediction from the $m$-th tree. Predicted probabilities are then given by:\n",
    "\n",
    "$$\\[ P(y = 1 \\mid X) = \\frac{1}{1 + e^{-F(x)}} \\]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e021a64-fb1e-4c68-b25a-07a7814112b2",
   "metadata": {},
   "source": [
    "___________________________________\n",
    "#### XGBoost\n",
    "\n",
    "XGBoost, like other gradient boosting methods, predicts probabilities by combining the predictions of multiple trees. The model computes a score $F(x)$, which is the sum of the predictions from individual trees weighted by the learning rate $\\eta$:\n",
    "\n",
    "$$\\[ F(x) = \\sum_{m=1}^{M} \\eta \\cdot h_m(x) \\]$$\n",
    "\n",
    "where $M$ is the number of trees, $\\eta$ is the learning rate, and $h_m(x)$ is the prediction from the $m$-th tree. The predicted probabilities are then given by:\n",
    "\n",
    "$$\\[ P(y = 1 \\mid X) = \\frac{1}{1 + e^{-F(x)}} \\]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296df3e-eb04-4c26-bf9f-48b2a1fdde7d",
   "metadata": {},
   "source": [
    "---------------\n",
    "# XGBoost model:\n",
    " ### XGB is a boosting machine learning model with a great performance. It's the first model considered since it has some PROs:\n",
    " - **High Predictive Accuracy**: it has a superior performance in predictive accuracy. It handles complex relationships and dependencies in data through ensemble learning techniques like gradient boosting\n",
    " - **Missing Values**: it handles very well the missing values. Reduces the preprocessing effots.\n",
    " - **Learning**: After the first predictions, the residuals are calculated and a new model is trained to predict those errors. The new predictions are added to the old model. This process in as many times as indicated. Below in \"param_grid_xgb\" we have n_estimators=450, which is the number of boosting rounds.\n",
    " - **Flexibility**: can handle a variety of data types and can be used for classification and regression.\n",
    " - **Scalability**: it can handle large datasets and can train them faster\n",
    " - **Regularization**: includes regularization techniques such as L1 and L2 ti prevent overfitting and improve generalization.\n",
    "      - **L1**: adds the abs. value of the coefficients to the loss function. It prodices sparse models, meaning it drives some coefficients to exactly zero. It is useful for identifying the most important features in the dataset. If $\\beta$ are the model coefficients, it adds $\\lambda \\sum_i |\\beta_i|$ to the loss function where $\\lambda$ is a regularization parameter that controls the strenght of the penalty\n",
    "      - **L2**: adds the squared values of the coefficients $\\lambda \\sum_i \\beta_i$ to the loss function. It distributes the penalty more evenly across all coefficients, shrinking the towards zero but not necessarily making theme xactly zero. This helps to keep all features in the model, reducing the risk of overfitting without eliminating any features.\n",
    " - **Feature Importance**: It helps to identify which features have the most impact on predictions and understand the underlying relationships in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0754cb0-48c1-414f-9a08-aa98c1ae76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#XGBoost model\n",
    "param_grid_xgb = { #the parameters were chosen manually after repeated attemps with different values. These gave the best AUC\n",
    "    'learning_rate': [0.04, 0.05, 0.03, 0.09], #values tipically between 0.01 and 0.3: For lower learning rate it provides more accuracy and less speed but also \n",
    "                            # can produce overfitting. The opposite happens with higher learning rate.\n",
    "    'n_estimators': [500, 400, 450], #number of boosting round\n",
    "    'max_depth':[14, 10, 12] #is the maximum depth of a tree. It controls the complexity of the model. Bigger the values the more complex patters\n",
    "                    #but it can lead to overfitting\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Set up the grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Get the best estimator\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "# Validate the model on the validation set\n",
    "y_val_pred_xgb = best_xgb_model.predict(X_val_scaled_df)\n",
    "y_val_pred_proba_xgb = best_xgb_model.predict_proba(X_val_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for validation set\n",
    "print(\"Validation Set Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred_xgb))\n",
    "\n",
    "# Print AUC score for validation set\n",
    "print(f\"AUC (Validation): {roc_auc_score(y_val, y_val_pred_proba_xgb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce30902e-e8bd-48b0-9328-ee4626d5defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize the XGBoost model with the best parameters extracted from GridSearchCV\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42, **best_params_xgb)\n",
    "\n",
    "# Train the model on the training data\n",
    "xgb_model.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_scaled_df)\n",
    "y_test_pred_proba_xgb = xgb_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for test set\n",
    "print(\"Test Set Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_xgb))\n",
    "\n",
    "# Print AUC score for test set\n",
    "print(f\"AUC (Test): {roc_auc_score(y_test, y_test_pred_proba_xgb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99151595-eba5-46dd-b326-17bd61f8fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba_xgb)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(y_test, y_test_pred_proba_xgb)\n",
    "\n",
    "# Feature importances for XGBoost\n",
    "xgb_importances = best_xgb_model.feature_importances_\n",
    "xgb_df = pd.DataFrame(data=xgb_importances, index=X_train_scaled_df.columns, columns=['Value']).sort_values('Value', ascending=False)\n",
    "\n",
    "# Create a 1x2 subplot layout\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot ROC curve\n",
    "axs[0].plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "axs[0].plot([0, 1], [0, 1], color='gray', linestyle='--')  # Plotting the diagonal line for random model\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_ylim([0.0, 1.05])\n",
    "axs[0].set_xlabel('False Positive Rate (FPR)')\n",
    "axs[0].set_ylabel('True Positive Rate (TPR)')\n",
    "axs[0].set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "axs[0].legend(loc='lower right')\n",
    "\n",
    "# Plot feature importances\n",
    "axs[1].barh(xgb_df.index, xgb_df['Value'], color='blue')\n",
    "axs[1].set_xlabel('Feature Importance')\n",
    "axs[1].set_ylabel('Feature Name')\n",
    "axs[1].set_title('XGBoost Feature Importances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006c440-31a9-4494-9bcc-92c972bcf7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot impact of top features on default probability\n",
    "def plot_feature_impact(top_features, model_name):\n",
    "    plt.figure(figsize=(15, 3))  # Adjust figsize as needed\n",
    "    num_features = len(top_features)\n",
    "    num_cols = 3  # Number of columns for subplots\n",
    "\n",
    "    # Calculate number of rows needed\n",
    "    num_rows = (num_features // num_cols) + (num_features % num_cols > 0)\n",
    "\n",
    "    for i, feature in enumerate(top_features):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        sns.regplot(x=X[feature], y=y, logistic=True, ci=None, scatter_kws={\"s\": 10, \"alpha\": 0.5})\n",
    "        plt.title(f'Impact of {feature} on Default ({model_name})')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Probability of Default')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for XGradient Boosting (GB) model\n",
    "top_features_xgb = xgb_df.head(3).index  # Select top 3 features for Gradient Boosting\n",
    "plot_feature_impact(top_features_xgb, 'Extreme Gradient Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a8ac5-5f07-48fc-b7cc-0623798c3348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for test set\n",
    "cm = confusion_matrix(y_test, y_test_pred_xgb)\n",
    "\n",
    "# Create ConfusionMatrixDisplay object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Default', 'Default'])\n",
    "\n",
    "# Plot confusion matrix with annotations\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='.4g')\n",
    "\n",
    "plt.title('Confusion Matrix - XGBoost Classifier (Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28fa12e-0c74-45ed-89a3-871dc79b1b75",
   "metadata": {},
   "source": [
    "# Random Forest Classifier model:\n",
    " ### It is an ensemble learning method that constructs a multitude of decision trees during training.\n",
    " - **Bootstrap Sampling**: Each tree in the Random Forest is trained on a bootstrap sample of the data, which involves randomly selecting samples with replacement from the training set.\n",
    " - **Feature Randomness**: At each split in the decision tree, a random subset of features is considered. This randomness helps to decorrelate the trees and reduce overfitting.\n",
    " - **Voting Mechanism**: For classification tasks, the final prediction of the Random Forest is determined by a majority vote (mode) of the predictions of its constituent trees.\n",
    " - **Handling of Missing Values**: It handles missing values in the dataset by using surrogate splits in the trees, reducing the need for imputation or preprocessing.\n",
    " - **Scalability**: It is scalable and can efficiently handle large datasets and high-dimensional feature spaces. The training process can be parallelized across multiple processors.\n",
    " - **Robust to Overfitting**: By averaging predictions across multiple trees (bagging) and introducing randomness in feature selection and tree construction, Random Forest tends to generalize well and is less prone to overfitting compared to individual decision trees.\n",
    " - **Easy to Tune**: Although it has several hyperparameters (e.g., number of trees, maximum depth of trees), it is relatively easier to tune compared to some other complex models like neural networks.\n",
    " - **Handling Imbalanced Data**: It handles imbalanced datasets by balancing class weights or using techniques like SMOTE (Synthetic Minority Over-sampling Technique) during training, which is beneficial for classification tasks with unequal class distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc038d72-0949-4f8d-8f02-8246bed66fa6",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31eabe-feea-4c0e-a4cf-3fa5bfb99e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Random Forest model\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [385, 380], #Higher values can improve performance at the cost of increased computational \n",
    "                                #resources and potential overfitting. Here, we are testing 370 and 380 trees.\n",
    "                                #Controls the number of decision trees in the forest.\n",
    "    \n",
    "    'max_depth': [None, 5, 1],#A deeper tree can model more complex relationships but increases the risk of overfitting\n",
    "    \n",
    "    'min_samples_split': [2],#Higher values prevent the model from learning overly specific patterns, potentially reducing overfitting.\n",
    "    \n",
    "    'min_samples_leaf': [1 ],# Similar to min_samples_split, higher values can prevent the model from becoming too specific. \n",
    "    'criterion': ['gini'],  # Criterion for splitting (you can test both)\n",
    "    'max_features': ['sqrt', None]  # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up the grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_model,param_grid=param_grid_rf, scoring='roc_auc', cv=10, n_jobs=-1, verbose=2, error_score='raise')\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params_rf = grid_search.best_params_\n",
    "print(f\"Best parameters found: {best_params_rf}\")\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Validate the model on the validation set\n",
    "y_val_pred_rf = best_rf_model.predict(X_val_scaled_df)\n",
    "y_val_pred_proba_rf = best_rf_model.predict_proba(X_val_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for validation set\n",
    "print(\"Validation Set Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "\n",
    "# Print AUC score for validation set\n",
    "print(f\"AUC (Validation): {roc_auc_score(y_val, y_val_pred_proba_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0e300-0a6a-4cec-9c99-a171a51709aa",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21844a87-f299-4339-903f-23b5dbaa5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize the RandomForestClassifier with the best parameters extracted from GridSearchCV\n",
    "rf_model = RandomForestClassifier(random_state=42, **best_params_rf)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Evaluate the final model on the test data\n",
    "y_test_pred_rf = rf_model.predict(X_test_scaled_df)\n",
    "y_test_pred_proba_rf = rf_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for test set\n",
    "print(\"Test Set Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_rf))\n",
    "\n",
    "# Print AUC score for test set\n",
    "print(f\"AUC (Test): {roc_auc_score(y_test, y_test_pred_proba_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd7c24-5abb-4497-a8b9-841cd0fdbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba_rf)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(y_test, y_test_pred_proba_rf)\n",
    "\n",
    "# Feature importances for Random Forest\n",
    "rf_importances = best_rf_model.feature_importances_\n",
    "rf_df = pd.DataFrame(data=rf_importances, index=X_train_scaled_df.columns, columns=['Value']).sort_values('Value', ascending=False)\n",
    "\n",
    "# Create a 1x2 subplot layout\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot ROC curve\n",
    "axs[0].plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "axs[0].plot([0, 1], [0, 1], color='gray', linestyle='--')  # Plotting the diagonal line for random model\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_ylim([0.0, 1.05])\n",
    "axs[0].set_xlabel('False Positive Rate (FPR)')\n",
    "axs[0].set_ylabel('True Positive Rate (TPR)')\n",
    "axs[0].set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "axs[0].legend(loc='lower right')\n",
    "\n",
    "# Plot feature importances\n",
    "axs[1].barh(rf_df.index, rf_df['Value'], color='green')\n",
    "axs[1].set_xlabel('Feature Importance')\n",
    "axs[1].set_ylabel('Feature Name')\n",
    "axs[1].set_title('Random Forest Feature Importances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3a4e0-c9a5-4a6d-82b5-c6fd3dbd9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot impact of top features on default probability\n",
    "def plot_feature_impact(top_features, model_name):\n",
    "    plt.figure(figsize=(15, 3))  # Adjust figsize as needed\n",
    "    num_features = len(top_features)\n",
    "    num_cols = 3  # Number of columns for subplots\n",
    "\n",
    "    # Calculate number of rows needed\n",
    "    num_rows = (num_features // num_cols) + (num_features % num_cols > 0)\n",
    "\n",
    "    for i, feature in enumerate(top_features):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        sns.regplot(x=X[feature], y=y, logistic=True, ci=None, scatter_kws={\"s\": 10, \"alpha\": 0.5})\n",
    "        plt.title(f'Impact of {feature} on Default ({model_name})')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Probability of Default')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for Gradient Boosting (GB) model\n",
    "top_features_rf = rf_df.head(3).index  # Select top 3 features for Gradient Boosting\n",
    "plot_feature_impact(top_features_rf, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d010386-c811-4a68-896c-dce590ab1310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for test set\n",
    "cm = confusion_matrix(y_test, y_test_pred_rf)\n",
    "\n",
    "# Create ConfusionMatrixDisplay object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Default', 'Default'])\n",
    "\n",
    "# Plot confusion matrix with annotations\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='.4g')\n",
    "\n",
    "plt.title('Confusion Matrix - Random Forest (Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603fa13-1823-42ff-9524-9e03c766c770",
   "metadata": {},
   "source": [
    "# Logistic Regression Model\n",
    "### It is a linear model that models the relationship between the dependent binary variable (Default and Non Default) and one or more indipendent variables using a logistic function\n",
    " - **Probabilistic Model**: It models the probability that an instance belongs to a particular class (usually the positive class) using the logistic (sigmoid) function, which maps any real-valued input to a value between 0 and 1.\n",
    " - **Binary Classification**: Logistic Regression is primarily used for binary classification tasks where the response variable is categorical with two levels (e.g., yes/no, 0/1).\n",
    " - **Coefficient Interpretation**: The coefficients (weights) learned by Logistic Regression represent the influence of each feature on the probability of the outcome. Positive coefficients indicate a positive association with the log-odds of the outcome, while negative coefficients indicate a negative association.\n",
    " - **Log-Likelihood Optimization**: it maximizes the likelihood function (or equivalently minimizes the negative log-likelihood) to estimate the optimal coefficients. This is typically done using optimization algorithms like Gradient Descent.\n",
    " - **Regularization**: Can include regularization techniques like L1 (Lasso) and L2 (Ridge) regularization to penalize large coefficients and prevent overfitting. This is controlled by the regularization parameter (C or λ).\n",
    "### CONS\n",
    "- **Feature Scaling**: Logistic Regression is sensitive to the scale of the features. It is common practice to scale features to a similar range (e.g., using StandardScaler) before fitting the model to ensure stable and optimal performance.\n",
    "- **Assumptions**: Logistic Regression assumes a linear relationship between the independent variables and the log-odds of the dependent variable. It also assumes that there is little or no multicollinearity among the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28d6254-ac5a-42e1-9c2c-fda947e42afe",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f7687-1f86-47f0-abe6-556dafef4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.5, 0.35, 0.6, 0.7, 0.4],  # Regularization parameter, by attempts, 0.7 is the best and 0.1 is the next best one\n",
    "    'penalty': ['l1', 'l2']# Regularization type, the more efficient is the l1.\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logistic_reg = LogisticRegression(max_iter=5000, solver='liblinear', random_state=42)\n",
    "\n",
    "# Set up the grid search with cross-validation\n",
    "grid_search_lr = GridSearchCV(estimator=logistic_reg, param_grid=param_grid_lr, scoring='roc_auc', cv=10, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search_lr.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "print(f\"Best parameters found: {best_params_lr}\")\n",
    "\n",
    "# Get the best estimator\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "# Validate the model on the validation set\n",
    "y_val_pred_lr = best_lr_model.predict(X_val_scaled_df)\n",
    "y_val_pred_proba_lr = best_lr_model.predict_proba(X_val_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for validation set\n",
    "print(\"Logistic Regression Validation Set Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred_lr))\n",
    "\n",
    "# Print AUC score for validation set\n",
    "print(f\"AUC (Validation): {roc_auc_score(y_val, y_val_pred_proba_lr):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f3c63-728c-4d45-96a4-60b95c806e1e",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188b595-5f20-4594-b37e-c8ce1283843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize the RandomForestClassifier with the best parameters extracted from GridSearchCV\n",
    "lr_model = LogisticRegression(max_iter=5000, solver='saga', random_state=42, **best_params_lr)\n",
    "\n",
    "# Train the model on the training data\n",
    "lr_model.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Evaluate the final model on the test data\n",
    "y_test_pred_lr = lr_model.predict(X_test_scaled_df)\n",
    "y_test_pred_proba_lr = lr_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for test set\n",
    "print(\"Logistic Regression Test Set Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_lr))\n",
    "\n",
    "# Print AUC score for test set\n",
    "print(f\"AUC (Test): {roc_auc_score(y_test, y_test_pred_proba_lr):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9c926-9e12-44b7-8daa-363127652343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba_lr)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(y_test, y_test_pred_proba_lr)\n",
    "\n",
    "# Get the coefficients of the model\n",
    "coefficients = np.append(best_lr_model.intercept_, best_lr_model.coef_.flatten())\n",
    "logistic_df = pd.DataFrame(data=coefficients, index=['Intercept'] + [col for col in X_train_scaled_df.columns], columns=['Value']).sort_values('Value', ascending=False)\n",
    "\n",
    "# Create a 1x2 subplot layout\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot ROC curve\n",
    "axs[0].plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "axs[0].plot([0, 1], [0, 1], color='gray', linestyle='--')  # Plotting the diagonal line for random model\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_ylim([0.0, 1.05])\n",
    "axs[0].set_xlabel('False Positive Rate (FPR)')\n",
    "axs[0].set_ylabel('True Positive Rate (TPR)')\n",
    "axs[0].set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "axs[0].legend(loc='lower right')\n",
    "\n",
    "# Plot logistic regression coefficients\n",
    "axs[1].barh(logistic_df.index, logistic_df['Value'], color='salmon')\n",
    "axs[1].set_xlabel('Coefficient Value')\n",
    "axs[1].set_ylabel('Feature Name')\n",
    "axs[1].set_title('Logistic Regression Coefficients')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f900b5-4eb6-472f-9440-10f7f74d9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot impact of top features on default probability\n",
    "def plot_feature_impact(top_features, model_name):\n",
    "    plt.figure(figsize=(15, 3))  # Adjust figsize as needed\n",
    "    num_features = len(top_features)\n",
    "    num_cols = 3  # Number of columns for subplots\n",
    "\n",
    "    # Calculate number of rows needed\n",
    "    num_rows = (num_features // num_cols) + (num_features % num_cols > 0)\n",
    "\n",
    "    for i, feature in enumerate(top_features):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        sns.regplot(x=X[feature], y=y, logistic=True, ci=None, scatter_kws={\"s\": 10, \"alpha\": 0.5})\n",
    "        plt.title(f'Impact of {feature} on Default ({model_name})')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Probability of Default')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for Gradient Boosting (GB) model\n",
    "top_features_lr = logistic_df.head(3).index  # Select top 3 features for Gradient Boosting\n",
    "plot_feature_impact(top_features_lr, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f2133-760a-4333-949c-dbe5e0187b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for test set\n",
    "cm = confusion_matrix(y_test, y_test_pred_lr)\n",
    "\n",
    "# Create ConfusionMatrixDisplay object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Default', 'Default'])\n",
    "\n",
    "# Plot confusion matrix with annotations\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='.4g')\n",
    "\n",
    "plt.title('Confusion Matrix - Logistic Regression (Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca3512-237e-423e-b36a-9b3860183b5f",
   "metadata": {},
   "source": [
    "# Decision Tree Model\n",
    "### It is a supervised machine learning algorithm used for both classification and regression tasks. It is a flowchart-like structure where each internal node represents a \"decision\" on a feature (or attribute), each branch represents the outcome of that decision, and each leaf node represents the final decision or the prediction label (class or value).\n",
    " - **Binary Splitting**: Decision Trees use recursive binary splitting to partition the data into subsets based on the values of features that best separate the target variable.\n",
    " - **Non-linear Model**: They can capture non-linear relationships between features and the target variable, making them suitable for complex datasets.\n",
    " - **Feature Importance**: They can rank features by their importance in predicting the target variable, based on metrics such as information gain (for classification) or variance reduction (for regression).\n",
    " - **Handling Mixed Data Types**: Decision Trees can handle both numerical and categorical data without requiring feature scaling.\n",
    " - **Splitting Criteria**: Common criteria for splitting nodes include Gini impurity and entropy for classification tasks, and variance reduction or mean squared error for regression tasks.\n",
    "\n",
    "### CONS\n",
    "- **Overfitting**: Without proper constraints (like pruning or limiting tree depth), Decision Trees can overfit the training data, capturing noise and details that do not generalize well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd86f9e-785f-43a5-a482-681ac7d41f0b",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144fc4e-5c39-499c-b610-cd12555efe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 10, 20, 1, 2], #Maximum depth of the tree. It controls the maximum number of levels in the decision tree\n",
    "                            #None: The tree is expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "                            #20: Limits the maximum depth to 30 levels.\n",
    "    \n",
    "    'min_samples_split': [2, 3, 10], #This param. ensures that a node in the decision tree must have at least 2 samples to be \n",
    "                                    #considered for further splitting.\n",
    "                                    #It helps control the complexity of the tree and can prevent the model from learning noise.\n",
    "    \n",
    "    'min_samples_leaf': [1,2,5,10] #This parameter sets the minimum number of samples required to be at a leaf node.\n",
    "                            #It ensures that each leaf node contains a sufficient number of samples to make robust predictions and prevents the model \n",
    "                            #from being too specific to the training data.\n",
    "    }                        \n",
    "# Initialize the DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize the GridSearchCV with the DecisionTreeClassifier and param_grid_dt\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid_dt, cv=10, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params_dt = grid_search.best_params_\n",
    "print(f\"Best parameters found: {best_params_dt}\")\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# Validate the model on the validation set\n",
    "y_val_pred_dt = best_dt_model.predict(X_val_scaled_df)\n",
    "y_val_pred_proba_dt = best_dt_model.predict_proba(X_val_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for validation set\n",
    "print(\"Decision Tree Validation Set Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred_dt))\n",
    "\n",
    "# Print AUC score for validation set\n",
    "print(f\"AUC (Validation): {roc_auc_score(y_val, y_val_pred_proba_dt):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58f654-7073-4411-b5f8-de2ba3b31b94",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d62d0-833d-4816-bae3-bf9055858e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Initialize the DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42,**best_params_dt)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "dt_model.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Validate the model on the validation set\n",
    "y_test_pred_dt = dt_model.predict(X_test_scaled_df)\n",
    "y_test_pred_proba_dt = dt_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for validation set\n",
    "print(\"Decision Tree Validation Set Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_dt))\n",
    "\n",
    "# Print AUC score for validation set\n",
    "print(f\"AUC (Validation): {roc_auc_score(y_test, y_test_pred_proba_dt):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06fceab-18b3-473d-b602-03cd5f737a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba_dt)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(y_test, y_test_pred_proba_dt)\n",
    "\n",
    "# Feature importances for Decision Tree\n",
    "dt_importances = best_dt_model.feature_importances_\n",
    "dt_df = pd.DataFrame(data=dt_importances, index=X_train_scaled_df.columns, columns=['Value']).sort_values('Value', ascending=False)\n",
    "\n",
    "# Create a 1x2 subplot layout\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot ROC curve\n",
    "axs[0].plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "axs[0].plot([0, 1], [0, 1], color='gray', linestyle='--')  # Plotting the diagonal line for random model\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_ylim([0.0, 1.05])\n",
    "axs[0].set_xlabel('False Positive Rate (FPR)')\n",
    "axs[0].set_ylabel('True Positive Rate (TPR)')\n",
    "axs[0].set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "axs[0].legend(loc='lower right')\n",
    "\n",
    "# Plot Decision Tree feature importances\n",
    "axs[1].barh(dt_df.index, dt_df['Value'], color='green')\n",
    "axs[1].set_xlabel('Feature Importance')\n",
    "axs[1].set_ylabel('Feature Name')\n",
    "axs[1].set_title('Decision Tree Feature Importances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a29d1-a007-4c80-8dd1-5a47a4a09594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot impact of top features on default probability\n",
    "def plot_feature_impact(top_features, model_name):\n",
    "    plt.figure(figsize=(15, 3))  # Adjust figsize as needed\n",
    "    num_features = len(top_features)\n",
    "    num_cols = 3  # Number of columns for subplots\n",
    "\n",
    "    # Calculate number of rows needed\n",
    "    num_rows = (num_features // num_cols) + (num_features % num_cols > 0)\n",
    "\n",
    "    for i, feature in enumerate(top_features):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        sns.regplot(x=X[feature], y=y, logistic=True, ci=None, scatter_kws={\"s\": 10, \"alpha\": 0.5})\n",
    "        plt.title(f'Impact of {feature} on Default ({model_name})')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Probability of Default')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for Gradient Boosting (GB) model\n",
    "top_features_dt = dt_df.head(3).index  # Select top 3 features for Gradient Boosting\n",
    "plot_feature_impact(top_features_dt, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfb9f3-c863-4c82-8bea-4b2ce84a49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for test set\n",
    "cm = confusion_matrix(y_test, y_test_pred_dt)\n",
    "\n",
    "# Create ConfusionMatrixDisplay object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Default', 'Default'])\n",
    "\n",
    "# Plot confusion matrix with annotations\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='.4g')\n",
    "\n",
    "plt.title('Confusion Matrix - Decision Tree (Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc68e99-3932-4079-9f26-88665ad08f2e",
   "metadata": {},
   "source": [
    "_______________________\n",
    "# AdaBoost Model\n",
    "#### It is an ensemble learning algorithm that combines multiple weak learners, typically decision stumps, to create a strong predictive model by iteratively focusing on and correcting the errors of previous learners.\n",
    "- **Boosting Performance**: normally gives a high accuracy by combining the strenghts of multiple weak learners and it reduces variance and bias\n",
    "- **Robust against overfitting**: By focusing on the hardest-to-classify samples, AdaBoost inherently reduces the risk of overfitting, especially when used with simple weak learners.\n",
    "- **Handling Imbalanced Data**: It assigns higher weights to misclassified instances, which helps in handling imbalanced datasets where certain classes are underrepresented.\n",
    "\n",
    "### CONS\n",
    "- **Sensitive to Noisy Data**:can be very sensitive to noisy data and outliers, as it will assign higher weights to these misclassified instances, potentially degrading model performance.\n",
    "- **Computational Complexity** : The iterative nature of AdaBoost, where each weak learner is trained sequentially, can lead to longer training times compared to other algorithms, especially with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f49c6-4aab-4034-8065-7b7e1f16fd9d",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5cfa5-030d-488c-a498-0dddea786b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid_ada_val = {'n_estimators': [530, 520, 536, 538],'learning_rate': [1.72, 1.73, 1.69,1.68]}\n",
    "\n",
    "# Initialize AdaBoost model\n",
    "ada_model = AdaBoostClassifier(algorithm='SAMME.R',random_state=42)\n",
    "\n",
    "# Set up the grid search with cross-validation\n",
    "grid_search_ada_val = GridSearchCV(estimator=ada_model, param_grid=param_grid_ada_val, scoring='roc_auc', cv=10, n_jobs=-1, verbose=2, error_score='raise')\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search_ada_val.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params_ada_val = grid_search_ada_val.best_params_\n",
    "print(f\"Best parameters found: {best_params_ada_val}\")\n",
    "\n",
    "# Get the best estimator\n",
    "best_ada_model_val = grid_search_ada_val.best_estimator_\n",
    "\n",
    "# Validate the model on the validation set\n",
    "y_val_pred_ada = best_ada_model_val.predict(X_val_scaled_df)\n",
    "y_val_pred_proba_ada = best_ada_model_val.predict_proba(X_val_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for validation set\n",
    "print(\"Validation Set Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred_ada))\n",
    "\n",
    "# Print AUC score for validation set\n",
    "print(f\"AUC (Validation): {roc_auc_score(y_val, y_val_pred_proba_ada):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee0d83-88f7-44d2-a2c3-8ab4094af58a",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031ac20-7584-40e9-827b-ad5eebffbc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ada_model = AdaBoostClassifier(algorithm='SAMME.R',random_state=42)\n",
    "# Fit the GridSearchCV to the training data\n",
    "ada_model.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Evaluate the final model on the test data\n",
    "y_test_pred_ada =ada_model.predict(X_test_scaled_df)\n",
    "y_test_pred_proba_ada =ada_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for test set\n",
    "print(\"Test Set Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_ada))\n",
    "\n",
    "# Print AUC score for test set\n",
    "print(f\"AUC (Test): {roc_auc_score(y_test, y_test_pred_proba_ada):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2114b0-649f-4cc5-be27-b0363732b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for AdaBoost\n",
    "fpr_ada, tpr_ada, thresholds_ada = roc_curve(y_test, y_test_pred_proba_ada)\n",
    "\n",
    "# Plotting ROC curve and confusion matrix\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plotting ROC curve for AdaBoost\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr_ada, tpr_ada, color='blue', lw=2, label='ROC curve (AdaBoost)')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Plotting the diagonal line for random model\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - AdaBoost')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Calculate and print AUC score for AdaBoost\n",
    "auc_score_ada = roc_auc_score(y_test, y_test_pred_proba_ada)\n",
    "plt.text(0.7, 0.3, f'AUC Score: {auc_score_ada:.4f}', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# Compute confusion matrix for AdaBoost\n",
    "cm_ada = confusion_matrix(y_test, y_test_pred_ada)\n",
    "\n",
    "# Create ConfusionMatrixDisplay object for AdaBoost\n",
    "disp_ada = ConfusionMatrixDisplay(confusion_matrix=cm_ada, display_labels=['Non-Default', 'Default'])\n",
    "\n",
    "# Plot confusion matrix with annotations for AdaBoost\n",
    "plt.subplot(1, 2, 2)\n",
    "disp_ada.plot(cmap='Blues', ax=plt.gca(), values_format='.4g')\n",
    "plt.title('Confusion Matrix - AdaBoost (Test Set)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af99320-ccd0-4c5a-8673-22da149b1bd1",
   "metadata": {},
   "source": [
    "_______________________\n",
    "# Gradient Boosting Model\n",
    "#### It is used for regression and classification tasks. It builds an ensemble of decision trees in a stage-wise fashion, where each subsequent tree attempts to correct the errors of the previous trees.\n",
    "- **High Predictive Accuracy**: delivers superior predictive performance compared to single decision trees or less complex ensemble methods.\n",
    "- **Flexibility**: Capable of handling a variety of loss functions (e.g., regression, classification, ranking).\n",
    "- **Feature Importance**: Provides insights into the importance of features in the dataset, aiding in feature selection and understanding model behavior.\n",
    "- **Handles Various Data Types**: Works with both numerical and categorical data.\n",
    "\n",
    "### CONS\n",
    "- **Computationally Intensive**:Training gradient boosting models can be time-consuming and resource-intensive, especially with large datasets.\n",
    "- **Prone to Overfitting**: Without proper tuning, gradient boosting models can overfit to the training data, leading to poor generalization on unseen data.\n",
    "- **Sensitivity to Noisy Data**: Gradient Boosting can be sensitive to noisy data and outliers, which might necessitate additional data preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432addb8-1482-4a62-bb06-b32a8bf52984",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126ab37-5db2-465a-9372-1e520bdb6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define parameter grid for Gradient Boosting\n",
    "param_grid_gb_val = {\n",
    "    'n_estimators': [200, 210], # Refers to the number of boosting stages (or trees) that will be iteratively built.\n",
    "                                    # Each boosting stage improves the model by correcting errors of the previous stages.\n",
    "                                    # After a certain amount of estimators, there's good chances of overfitting.\n",
    "                                    # higher values makes the model more complex but also we risk overfitting \n",
    "    \n",
    "    'learning_rate': [0.25, 0.3], #controls the contribution of each tree to the model. It scales the contribution \n",
    "                                    # of each tree by multiplying the predictions of each tree by this learning rate.\n",
    "                                    # lower learning rate makes the model more robust by shrinking the contribution of each tree. This reduces\n",
    "                                    # overfitting.\n",
    "    \n",
    "    'max_depth': [10, 11]       # Determines the maximum depth of each tree in the boosting process. Depth is the number of nodes from \n",
    "                                    # the root to the farthest leaf node.\n",
    "                                    # Helps prevent overfitting. A deeper tree can model more complex relationships in the data but may also \n",
    "                                    # memorize noise in the training data, reducing generalization to new data.\n",
    "}\n",
    "\n",
    "# Initialize Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Set up the GridSearchCV with the model and parameter grid\n",
    "grid_search_val = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb_val, scoring='roc_auc', cv=10, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "grid_search_val.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params_gb = grid_search_val.best_params_\n",
    "print(f\"Best parameters found: {best_params_gb}\")\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_gb_model_val = grid_search_val.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_val_pred_gb_val = best_gb_model_val.predict(X_val_scaled_df)\n",
    "y_val_pred_proba_gb_val = best_gb_model_val.predict_proba(X_val_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for validation set\n",
    "print(\"Validation Set Classification Report\")\n",
    "print(classification_report(y_val, y_val_pred_gb_val))\n",
    "\n",
    "# Print AUC score for validation set\n",
    "print(f\"AUC (Validation): {roc_auc_score(y_val, y_val_pred_proba_gb_val):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a0ea2-114e-4d0c-b571-170face3ffe3",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b121f1a-cb15-45dc-a7af-7821e20cb8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "gb_model.fit(X_train_scaled_df, y_train_sm)\n",
    "\n",
    "# Evaluate the final model on the test data\n",
    "y_test_pred_gb_test = gb_model.predict(X_test_scaled_df)\n",
    "y_test_pred_proba_gb_test = gb_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "# Print classification report for test set\n",
    "print(\"Test Set Classification Report\")\n",
    "print(classification_report(y_test, y_test_pred_gb_test))\n",
    "\n",
    "# Print AUC score for test set\n",
    "print(f\"AUC (Test): {roc_auc_score(y_test, y_test_pred_proba_gb_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ce531-ebda-441b-9588-0582d7cdc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba_gb_test)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(y_test, y_test_pred_proba_gb_test)\n",
    "\n",
    "# Feature importances for Gradient Boosting\n",
    "gb_importances = gb_model.feature_importances_\n",
    "gb_df = pd.DataFrame(data=gb_importances, index=X_train.columns, columns=['Value']).sort_values('Value', ascending=False)\n",
    "\n",
    "# Create a 1x2 subplot layout\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "# Plot ROC curve\n",
    "axs[0].plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "axs[0].plot([0, 1], [0, 1], color='gray', linestyle='--')  # Plotting the diagonal line for random model\n",
    "axs[0].set_xlim([0.0, 1.0])\n",
    "axs[0].set_ylim([0.0, 1.05])\n",
    "axs[0].set_xlabel('False Positive Rate (FPR)')\n",
    "axs[0].set_ylabel('True Positive Rate (TPR)')\n",
    "axs[0].set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "axs[0].legend(loc='lower right')\n",
    "\n",
    "# Plot Gradient Boosting feature importances\n",
    "axs[1].barh(gb_df.index, gb_df['Value'], color='green')\n",
    "axs[1].set_xlabel('Feature Importance')\n",
    "axs[1].set_ylabel('Feature Name')\n",
    "axs[1].set_title('Gradient Boosting Feature Importances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60048c5f-5061-41ab-8f5c-525bf525dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot impact of top features on default probability\n",
    "def plot_feature_impact(top_features, model_name):\n",
    "    plt.figure(figsize=(15, 3))  # Adjust figsize as needed\n",
    "    num_features = len(top_features)\n",
    "    num_cols = 3  # Number of columns for subplots\n",
    "\n",
    "    # Calculate number of rows needed\n",
    "    num_rows = (num_features // num_cols) + (num_features % num_cols > 0)\n",
    "\n",
    "    for i, feature in enumerate(top_features):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        sns.regplot(x=X[feature], y=y, logistic=True, ci=None, scatter_kws={\"s\": 10, \"alpha\": 0.5})\n",
    "        plt.title(f'Impact of {feature} on Default ({model_name})')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Probability of Default')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for Gradient Boosting (GB) model\n",
    "top_features_gb = gb_df.head(3).index  # Select top 3 features for Gradient Boosting\n",
    "plot_feature_impact(top_features_gb, 'Gradient Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8e005-1fb6-40ea-a17b-bd694df1f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for test set\n",
    "cm = confusion_matrix(y_test, y_test_pred_gb_test)\n",
    "\n",
    "# Create ConfusionMatrixDisplay object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Default', 'Default'])\n",
    "\n",
    "# Plot confusion matrix with annotations\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='.4g')\n",
    "\n",
    "plt.title('Confusion Matrix - Gradient Boosting Classifier (Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27829c61-79b5-43dd-a4af-5e9b90db3442",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ca659-bbce-4ee9-8c87-a90e217217ce",
   "metadata": {},
   "source": [
    "### Some analysis regarding the output\n",
    "#### Following, we can see the dataset TEST with:\n",
    "- First column is the id of the individual\n",
    "- Second column is the actual default/non default\n",
    "- Each sequent column is the predicted default/non default of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cddf53-0a35-40a3-8f0b-fce6076400e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_actual = y_test  # Actual default/non-default values from the test set\n",
    "predictions={\n",
    "    'Actual': y_test_actual,\n",
    "    'XGBoost': y_test_pred_xgb,\n",
    "    'RandomForest': y_test_pred_rf,\n",
    "    'LogisticRegression': y_test_pred_lr,\n",
    "    'Decision Tree': y_test_pred_dt,\n",
    "    'AdaBoost': y_test_pred_ada,\n",
    "    'Gradient Boosting': y_test_pred_gb_test   \n",
    "}\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "from IPython.display import display\n",
    "display(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ed6e7-74ce-4d56-80ca-91e3c21d1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for defaulted observations (Actual == 1)\n",
    "defaulted_df = predictions_df[predictions_df['Actual'] == 1]\n",
    "\n",
    "# Get model names\n",
    "model_names = ['XGBoost', 'RandomForest', 'LogisticRegression', 'Decision Tree', 'AdaBoost', 'Gradient Boosting']\n",
    "\n",
    "# Initialize a DataFrame to hold the number of correct predictions for model pairs\n",
    "pair_matrix = pd.DataFrame(index=model_names, columns=model_names, data=0)\n",
    "\n",
    "# Calculate the number of correct predictions for each pair of models\n",
    "for model1, model2 in combinations(model_names, 2):\n",
    "    # Get predictions for the pair of models\n",
    "    pred1 = defaulted_df[model1]\n",
    "    pred2 = defaulted_df[model2]\n",
    "    \n",
    "    # Calculate the number of correct predictions where both models are correct\n",
    "    correct_predictions = np.sum((pred1 == defaulted_df['Actual']) & (pred2 == defaulted_df['Actual']))\n",
    "    \n",
    "    # Store the number of correct predictions in the matrix\n",
    "    pair_matrix.loc[model1, model2] = correct_predictions\n",
    "    pair_matrix.loc[model2, model1] = correct_predictions\n",
    "\n",
    "# Display the matrix\n",
    "print(pair_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755b71a-92e1-44f4-9e23-3c70d3eefb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for defaulted observations (Actual == 1)\n",
    "defaulted_df = predictions_df[predictions_df['Actual'] == 1]\n",
    "\n",
    "# Get model names\n",
    "model_names = ['XGBoost', 'RandomForest', 'LogisticRegression', 'Decision Tree', 'AdaBoost', 'Gradient Boosting']\n",
    "\n",
    "# Initialize a DataFrame to hold the number of correct predictions for model pairs\n",
    "pair_matrix = pd.DataFrame(index=model_names, columns=model_names, data=0)\n",
    "\n",
    "# Calculate the number of correct predictions for each pair of models\n",
    "for model1, model2 in combinations(model_names, 2):\n",
    "    # Get predictions for the pair of models\n",
    "    pred1 = defaulted_df[model1]\n",
    "    pred2 = defaulted_df[model2]\n",
    "    \n",
    "    # Calculate the number of correct predictions where both models are correct\n",
    "    correct_predictions = np.sum((pred1 == defaulted_df['Actual']) & (pred2 == defaulted_df['Actual']))\n",
    "    \n",
    "    # Store the number of correct predictions in the matrix\n",
    "    pair_matrix.loc[model1, model2] = correct_predictions\n",
    "    pair_matrix.loc[model2, model1] = correct_predictions\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cax = ax.matshow(pair_matrix, cmap='viridis')\n",
    "\n",
    "# Add color bar\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xticks(np.arange(len(model_names)))\n",
    "ax.set_yticks(np.arange(len(model_names)))\n",
    "ax.set_xticklabels(model_names)\n",
    "ax.set_yticklabels(model_names)\n",
    "\n",
    "# Rotate the x labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Annotate each cell with the numeric value\n",
    "for i in range(len(model_names)):\n",
    "    for j in range(len(model_names)):\n",
    "        ax.text(j, i, pair_matrix.iloc[i, j], va='center', ha='center')\n",
    "\n",
    "plt.title('Number of Correct Predictions for Each Pair of Models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a37d18-6b39-4c57-855e-b4015dd11798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add counts on bars\n",
    "def add_bar_labels(ax, bars):\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval, int(yval), va='bottom', ha='center')\n",
    "\n",
    "# Plot for REASON distribution\n",
    "total_reason = data['REASON'].value_counts().sort_index()\n",
    "default_reason = data[data['BAD'] == 1]['REASON'].value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "total_bars = ax.bar(total_reason.index - 0.2, total_reason, width=0.4, label='Total', align='center')\n",
    "default_bars = ax.bar(default_reason.index + 0.2, default_reason, width=0.4, label='Defaulters', align='center')\n",
    "\n",
    "# Adding labels and title for REASON\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(['DebtCon', 'HomeImp'])  # Assuming your REASON labels are DebtCon = 0, HomeImp = 1\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of Total vs Defaulters for REASON')\n",
    "ax.legend()\n",
    "\n",
    "# Add counts on the bars for REASON\n",
    "add_bar_labels(ax, total_bars)\n",
    "add_bar_labels(ax, default_bars)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot for JOB distribution\n",
    "total_job = data['JOB'].value_counts().sort_index()\n",
    "default_job = data[data['BAD'] == 1]['JOB'].value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "total_bars = ax.bar(total_job.index - 0.2, total_job, width=0.4, label='Total', align='center')\n",
    "default_bars = ax.bar(default_job.index + 0.2, default_job, width=0.4, label='Defaulters', align='center')\n",
    "\n",
    "# Adding labels and title for JOB\n",
    "job_labels = ['Other', 'Office', 'Mgr', 'ProfExe', 'Sales', 'Self']  # JOB labels as per your mapping\n",
    "ax.set_xticks(range(6))\n",
    "ax.set_xticklabels(job_labels)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of Total vs Defaulters for JOB')\n",
    "ax.legend()\n",
    "\n",
    "# Add counts on the bars for JOB\n",
    "add_bar_labels(ax, total_bars)\n",
    "add_bar_labels(ax, default_bars)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
